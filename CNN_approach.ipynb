{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMXjHZQSa47JOTgVieSE4VC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rohandhiman5/Kaggle-challenge-by-cynaptics-club/blob/main/CNN_approach.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOwVlu2Amo1G",
        "outputId": "758d2230-a644-4fdd-ed61-f12b6200186f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading spot-the-synthetic.zip to /content\n",
            " 91% 29.0M/31.8M [00:00<00:00, 65.3MB/s]\n",
            "100% 31.8M/31.8M [00:00<00:00, 57.7MB/s]\n"
          ]
        }
      ],
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle competitions download spot-the-synthetic"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "file = 'spot-the-synthetic.zip'\n",
        "with ZipFile(file, 'r') as zip:\n",
        "    zip.extractall()"
      ],
      "metadata": {
        "id": "d7-X2Mi-n1Tb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "MnLbiVHtonqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "isGMmaXlp83O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_preprocess_images_from_folder(folder, target_size=(224,224)):\n",
        "    images = []\n",
        "    for filename in os.listdir(folder):\n",
        "        img = Image.open(os.path.join(folder, filename))\n",
        "        if img is not None:\n",
        "            img.thumbnail(target_size, Image.ANTIALIAS)\n",
        "            new_img = Image.new(\"RGB\", target_size, (255, 255, 255))\n",
        "            new_img.paste(img, ((target_size[0] - img.size[0]) // 2, (target_size[1] - img.size[1]) // 2))\n",
        "            img_array = np.array(new_img).astype('float32') / 255.0\n",
        "            images.append(img_array)\n",
        "    return np.array(images)\n"
      ],
      "metadata": {
        "id": "ToCSnoVBqJyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ai_images = load_and_preprocess_images_from_folder('/content/Data/AI_Images')\n",
        "real_images = load_and_preprocess_images_from_folder('/content/Data/Real_Images')\n",
        "test_images = load_and_preprocess_images_from_folder('/content/Data/Test_Images')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3S4YaQ_qdqN",
        "outputId": "fbb320b6-e94a-406e-a574-b7b78e788fd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-aa644e78db35>:6: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
            "  img.thumbnail(target_size, Image.ANTIALIAS)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ai_images[55]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GeXGtmJz7mam",
        "outputId": "f556750d-b0ee-4362-b42b-f142d2687e3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0.8352941 , 0.8352941 , 0.8352941 ],\n",
              "        [0.89411765, 0.89411765, 0.89411765],\n",
              "        [0.85882354, 0.85882354, 0.85882354],\n",
              "        ...,\n",
              "        [0.8901961 , 0.8901961 , 0.8901961 ],\n",
              "        [0.8901961 , 0.8901961 , 0.8901961 ],\n",
              "        [0.8901961 , 0.8901961 , 0.8901961 ]],\n",
              "\n",
              "       [[0.84313726, 0.84313726, 0.84313726],\n",
              "        [0.8784314 , 0.8784314 , 0.8784314 ],\n",
              "        [0.827451  , 0.827451  , 0.827451  ],\n",
              "        ...,\n",
              "        [0.9098039 , 0.9098039 , 0.9098039 ],\n",
              "        [0.90588236, 0.90588236, 0.90588236],\n",
              "        [0.90588236, 0.90588236, 0.90588236]],\n",
              "\n",
              "       [[0.85490197, 0.85490197, 0.85490197],\n",
              "        [0.8666667 , 0.8666667 , 0.8666667 ],\n",
              "        [0.8156863 , 0.8156863 , 0.8156863 ],\n",
              "        ...,\n",
              "        [0.8980392 , 0.8980392 , 0.8980392 ],\n",
              "        [0.8980392 , 0.8980392 , 0.8980392 ],\n",
              "        [0.89411765, 0.89411765, 0.89411765]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0.7921569 , 0.7921569 , 0.7921569 ],\n",
              "        [0.81960785, 0.81960785, 0.81960785],\n",
              "        [0.8       , 0.8       , 0.8       ],\n",
              "        ...,\n",
              "        [0.88235295, 0.88235295, 0.88235295],\n",
              "        [0.89411765, 0.89411765, 0.89411765],\n",
              "        [0.90588236, 0.90588236, 0.90588236]],\n",
              "\n",
              "       [[0.77254903, 0.77254903, 0.77254903],\n",
              "        [0.79607844, 0.79607844, 0.79607844],\n",
              "        [0.80784315, 0.80784315, 0.80784315],\n",
              "        ...,\n",
              "        [0.84313726, 0.84313726, 0.84313726],\n",
              "        [0.88235295, 0.88235295, 0.88235295],\n",
              "        [0.8784314 , 0.8784314 , 0.8784314 ]],\n",
              "\n",
              "       [[0.8       , 0.8       , 0.8       ],\n",
              "        [0.7921569 , 0.7921569 , 0.7921569 ],\n",
              "        [0.8117647 , 0.8117647 , 0.8117647 ],\n",
              "        ...,\n",
              "        [0.7921569 , 0.7921569 , 0.7921569 ],\n",
              "        [0.8627451 , 0.8627451 , 0.8627451 ],\n",
              "        [0.8509804 , 0.8509804 , 0.8509804 ]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ai_labels = np.zeros(len(ai_images))\n",
        "real_labels = np.ones(len(real_images))\n",
        "ai_images.shape\n"
      ],
      "metadata": {
        "id": "-E9CHxfjv378",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e2098eb-5f51-4ca3-b2a2-7392e0a02079"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(655, 224, 224, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "real_images.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNA5qbUc8bZY",
        "outputId": "a8463af6-efd8-4474-87eb-70f859b30b2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(600, 224, 224, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.concatenate((ai_images, real_images), axis=0)\n",
        "y_train = np.concatenate((ai_labels, real_labels), axis=0)\n"
      ],
      "metadata": {
        "id": "QGA3GccYv3dN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape of X_train:\", X_train.shape)\n",
        "print(\"Shape of y_train:\", y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IeQNzx5tqoL5",
        "outputId": "f076920e-8732-4725-adf9-5656c9efbab4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X_train: (1255, 224, 224, 3)\n",
            "Shape of y_train: (1255,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[:2]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gwvv5fTqrGi",
        "outputId": "325a040a-deb6-49bb-bf09-614a67d8deb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train=y_train.reshape(-1,)"
      ],
      "metadata": {
        "id": "vZoDu0Z1rU5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[:2 ]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkQckAWjFcht",
        "outputId": "19d077c7-729d-4eb4-dffd-243f9dae3664"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[:1]"
      ],
      "metadata": {
        "id": "HYveQPniFhFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras import layers\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "metadata": {
        "id": "IRiYv3qjTwh8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation = keras.Sequential(\n",
        "  [\n",
        "    layers.experimental.preprocessing.RandomFlip(\"horizontal\",\n",
        "                                                 input_shape=(224,\n",
        "                                                              224,\n",
        "                                                              3)),\n",
        "    layers.experimental.preprocessing.RandomRotation(0.1),\n",
        "    layers.experimental.preprocessing.RandomZoom(0.1),\n",
        "  ]\n",
        ")"
      ],
      "metadata": {
        "id": "AdS6nSGQ6p_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 2\n",
        "\n",
        "model = Sequential([\n",
        "  data_augmentation,\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Dropout(0.2),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(2, activation='sigmoid'),\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, y_train, epochs=30)"
      ],
      "metadata": {
        "id": "CoyrJIaW6p1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e912fd41-8324-4bc8-abae-eef640ebe309"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/backend.py:5727: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40/40 [==============================] - 4s 45ms/step - loss: 0.9291 - accuracy: 0.5745\n",
            "Epoch 2/30\n",
            "40/40 [==============================] - 2s 43ms/step - loss: 0.6674 - accuracy: 0.5801\n",
            "Epoch 3/30\n",
            "40/40 [==============================] - 2s 43ms/step - loss: 0.6395 - accuracy: 0.6104\n",
            "Epoch 4/30\n",
            "40/40 [==============================] - 2s 47ms/step - loss: 0.6422 - accuracy: 0.6414\n",
            "Epoch 5/30\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.6309 - accuracy: 0.6303\n",
            "Epoch 6/30\n",
            "40/40 [==============================] - 2s 42ms/step - loss: 0.6107 - accuracy: 0.6598\n",
            "Epoch 7/30\n",
            "40/40 [==============================] - 2s 43ms/step - loss: 0.6096 - accuracy: 0.6614\n",
            "Epoch 8/30\n",
            "40/40 [==============================] - 2s 42ms/step - loss: 0.5973 - accuracy: 0.6829\n",
            "Epoch 9/30\n",
            "40/40 [==============================] - 2s 42ms/step - loss: 0.5914 - accuracy: 0.6813\n",
            "Epoch 10/30\n",
            "40/40 [==============================] - 2s 42ms/step - loss: 0.5858 - accuracy: 0.6845\n",
            "Epoch 11/30\n",
            "40/40 [==============================] - 2s 46ms/step - loss: 0.5768 - accuracy: 0.6916\n",
            "Epoch 12/30\n",
            "40/40 [==============================] - 2s 44ms/step - loss: 0.5713 - accuracy: 0.6900\n",
            "Epoch 13/30\n",
            "40/40 [==============================] - 2s 43ms/step - loss: 0.5539 - accuracy: 0.6964\n",
            "Epoch 14/30\n",
            "40/40 [==============================] - 2s 43ms/step - loss: 0.5484 - accuracy: 0.7155\n",
            "Epoch 15/30\n",
            "40/40 [==============================] - 2s 43ms/step - loss: 0.5520 - accuracy: 0.7131\n",
            "Epoch 16/30\n",
            "40/40 [==============================] - 2s 43ms/step - loss: 0.5417 - accuracy: 0.7235\n",
            "Epoch 17/30\n",
            "40/40 [==============================] - 2s 43ms/step - loss: 0.5302 - accuracy: 0.7267\n",
            "Epoch 18/30\n",
            "40/40 [==============================] - 2s 47ms/step - loss: 0.5344 - accuracy: 0.7235\n",
            "Epoch 19/30\n",
            "40/40 [==============================] - 2s 45ms/step - loss: 0.5255 - accuracy: 0.7291\n",
            "Epoch 20/30\n",
            "40/40 [==============================] - 2s 42ms/step - loss: 0.5282 - accuracy: 0.7434\n",
            "Epoch 21/30\n",
            "40/40 [==============================] - 2s 43ms/step - loss: 0.5158 - accuracy: 0.7267\n",
            "Epoch 22/30\n",
            "40/40 [==============================] - 2s 43ms/step - loss: 0.5049 - accuracy: 0.7490\n",
            "Epoch 23/30\n",
            "40/40 [==============================] - 2s 43ms/step - loss: 0.4873 - accuracy: 0.7610\n",
            "Epoch 24/30\n",
            "15/40 [==========>...................] - ETA: 1s - loss: 0.5019 - accuracy: 0.7396"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yNE7t1qT6pqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''cnn = models.Sequential([\n",
        "    layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(32,32, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(2, activation='softmax')\n",
        "])'''"
      ],
      "metadata": {
        "id": "tCB3jI_hFvHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''cnn.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])'''"
      ],
      "metadata": {
        "id": "nH6IbsKDF-YW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''cnn.fit(X_train, y_train, epochs=15)'''"
      ],
      "metadata": {
        "id": "5f1-DyT6GCOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_images = load_and_preprocess_images_from_folder('/content/Data/Test_Images')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAYoJseKGE21",
        "outputId": "27e778ba-3fab-491d-9358-90ae43a3094e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-aa644e78db35>:6: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
            "  img.thumbnail(target_size, Image.ANTIALIAS)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test=test_images\n",
        "X_test.shape"
      ],
      "metadata": {
        "id": "pf8idah_KgXZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e183e61f-e806-46b0-b55c-b71eda49ff81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(500, 224, 224, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_pred[:]"
      ],
      "metadata": {
        "id": "MuySfa6BKjP2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "416d956e-1f16-4a97-a6bc-2ca186f810eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 [==============================] - 1s 34ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.5108174 , 0.39937377],\n",
              "       [0.5400308 , 0.27735117],\n",
              "       [0.6939379 , 0.28918165],\n",
              "       [0.7908977 , 0.19137125],\n",
              "       [0.41693977, 0.5045125 ],\n",
              "       [0.34154072, 0.72604996],\n",
              "       [0.3441672 , 0.56564   ],\n",
              "       [0.20627572, 0.6292523 ],\n",
              "       [0.63398856, 0.2458406 ],\n",
              "       [0.22572026, 0.62520707],\n",
              "       [0.3712253 , 0.46975422],\n",
              "       [0.5379785 , 0.3637912 ],\n",
              "       [0.3044286 , 0.53125125],\n",
              "       [0.56034654, 0.3183785 ],\n",
              "       [0.4943736 , 0.6033996 ],\n",
              "       [0.03406928, 0.8350109 ],\n",
              "       [0.43031865, 0.39632553],\n",
              "       [0.32297787, 0.44988734],\n",
              "       [0.15038502, 0.77025664],\n",
              "       [0.2819838 , 0.58941203],\n",
              "       [0.6608932 , 0.3327361 ],\n",
              "       [0.4053105 , 0.44163176],\n",
              "       [0.13790864, 0.7530801 ],\n",
              "       [0.44059074, 0.34526068],\n",
              "       [0.58902776, 0.3771272 ],\n",
              "       [0.6363519 , 0.2936355 ],\n",
              "       [0.43543878, 0.35338   ],\n",
              "       [0.42985868, 0.44530824],\n",
              "       [0.2383144 , 0.6145223 ],\n",
              "       [0.12167673, 0.6979606 ],\n",
              "       [0.17515704, 0.70360476],\n",
              "       [0.924537  , 0.08237405],\n",
              "       [0.5293903 , 0.27877712],\n",
              "       [0.39948377, 0.45487252],\n",
              "       [0.33100846, 0.5347605 ],\n",
              "       [0.21630138, 0.54217434],\n",
              "       [0.42935547, 0.46591285],\n",
              "       [0.4576373 , 0.36632413],\n",
              "       [0.39644942, 0.4290784 ],\n",
              "       [0.43088904, 0.41616735],\n",
              "       [0.8645893 , 0.08903868],\n",
              "       [0.1123081 , 0.72630167],\n",
              "       [0.35495898, 0.48679176],\n",
              "       [0.3922704 , 0.48280737],\n",
              "       [0.56105715, 0.22239657],\n",
              "       [0.6003519 , 0.4604086 ],\n",
              "       [0.16557544, 0.6981594 ],\n",
              "       [0.327845  , 0.5206088 ],\n",
              "       [0.6607991 , 0.21516258],\n",
              "       [0.3570169 , 0.4298536 ],\n",
              "       [0.30746615, 0.5177296 ],\n",
              "       [0.35957974, 0.4439832 ],\n",
              "       [0.11260306, 0.7478421 ],\n",
              "       [0.45483345, 0.46073452],\n",
              "       [0.4261655 , 0.4691027 ],\n",
              "       [0.55813926, 0.40298626],\n",
              "       [0.5487395 , 0.30120564],\n",
              "       [0.6913977 , 0.26115245],\n",
              "       [0.38080594, 0.52973574],\n",
              "       [0.67357147, 0.29182443],\n",
              "       [0.30133125, 0.5342326 ],\n",
              "       [0.3193859 , 0.71742964],\n",
              "       [0.13178368, 0.67768276],\n",
              "       [0.49498454, 0.7041716 ],\n",
              "       [0.43594608, 0.42824265],\n",
              "       [0.3430236 , 0.51689905],\n",
              "       [0.3598219 , 0.49614486],\n",
              "       [0.31964272, 0.55124855],\n",
              "       [0.60941523, 0.37309387],\n",
              "       [0.49399802, 0.38359195],\n",
              "       [0.305831  , 0.50443524],\n",
              "       [0.83584106, 0.11526649],\n",
              "       [0.61225355, 0.37240145],\n",
              "       [0.40117532, 0.44539574],\n",
              "       [0.5365961 , 0.5920182 ],\n",
              "       [0.42797425, 0.46716535],\n",
              "       [0.1102431 , 0.70324636],\n",
              "       [0.68281734, 0.33813795],\n",
              "       [0.05622238, 0.7739208 ],\n",
              "       [0.2565014 , 0.3806114 ],\n",
              "       [0.7953379 , 0.1507178 ],\n",
              "       [0.57181215, 0.31492305],\n",
              "       [0.340229  , 0.5180246 ],\n",
              "       [0.19914411, 0.6348781 ],\n",
              "       [0.43212405, 0.39577007],\n",
              "       [0.47147566, 0.4203191 ],\n",
              "       [0.34492886, 0.58289844],\n",
              "       [0.7256951 , 0.1854787 ],\n",
              "       [0.44277352, 0.50461054],\n",
              "       [0.3537348 , 0.46836278],\n",
              "       [0.0374128 , 0.86010516],\n",
              "       [0.5765795 , 0.305198  ],\n",
              "       [0.16343422, 0.63847935],\n",
              "       [0.32819435, 0.52142835],\n",
              "       [0.5979934 , 0.44546345],\n",
              "       [0.34547335, 0.50494236],\n",
              "       [0.4085136 , 0.47298753],\n",
              "       [0.15236859, 0.6334416 ],\n",
              "       [0.32131726, 0.5278527 ],\n",
              "       [0.30709937, 0.5763476 ],\n",
              "       [0.4828828 , 0.39574447],\n",
              "       [0.3497323 , 0.43009165],\n",
              "       [0.6037111 , 0.44314906],\n",
              "       [0.31421036, 0.52642983],\n",
              "       [0.35534656, 0.51543325],\n",
              "       [0.37727922, 0.32951954],\n",
              "       [0.29609877, 0.57317454],\n",
              "       [0.23167314, 0.5725187 ],\n",
              "       [0.28209674, 0.5676046 ],\n",
              "       [0.5164369 , 0.279965  ],\n",
              "       [0.7482058 , 0.19509205],\n",
              "       [0.3918166 , 0.5475276 ],\n",
              "       [0.4559033 , 0.41449484],\n",
              "       [0.14058295, 0.67465454],\n",
              "       [0.7637961 , 0.20437238],\n",
              "       [0.3001628 , 0.53437525],\n",
              "       [0.62380725, 0.1686819 ],\n",
              "       [0.6888246 , 0.2984097 ],\n",
              "       [0.34791794, 0.5134057 ],\n",
              "       [0.24532233, 0.6073849 ],\n",
              "       [0.5812907 , 0.30034506],\n",
              "       [0.69028044, 0.21828105],\n",
              "       [0.24810578, 0.5507968 ],\n",
              "       [0.01119596, 0.9197404 ],\n",
              "       [0.5618968 , 0.30975035],\n",
              "       [0.33956575, 0.51779336],\n",
              "       [0.65487313, 0.3598718 ],\n",
              "       [0.6967687 , 0.19685505],\n",
              "       [0.23092137, 0.5366112 ],\n",
              "       [0.3327538 , 0.52217263],\n",
              "       [0.33882862, 0.47420663],\n",
              "       [0.02180798, 0.8890137 ],\n",
              "       [0.5442447 , 0.34493294],\n",
              "       [0.6229057 , 0.33610666],\n",
              "       [0.28744447, 0.57290196],\n",
              "       [0.33531314, 0.5569756 ],\n",
              "       [0.33006686, 0.5212418 ],\n",
              "       [0.73748857, 0.09333724],\n",
              "       [0.7714194 , 0.18090533],\n",
              "       [0.3873711 , 0.51242536],\n",
              "       [0.6772165 , 0.27546325],\n",
              "       [0.52586645, 0.2274396 ],\n",
              "       [0.3761821 , 0.4655343 ],\n",
              "       [0.32388532, 0.5244109 ],\n",
              "       [0.33360943, 0.5014209 ],\n",
              "       [0.54397815, 0.33668584],\n",
              "       [0.13414331, 0.72325474],\n",
              "       [0.5210279 , 0.3326924 ],\n",
              "       [0.48909688, 0.368302  ],\n",
              "       [0.24583094, 0.6549303 ],\n",
              "       [0.33352992, 0.47961822],\n",
              "       [0.77620447, 0.16800052],\n",
              "       [0.08669049, 0.70034814],\n",
              "       [0.8245101 , 0.19574334],\n",
              "       [0.4496979 , 0.48615313],\n",
              "       [0.6797523 , 0.27157873],\n",
              "       [0.37314367, 0.46687394],\n",
              "       [0.48137677, 0.40889964],\n",
              "       [0.23410025, 0.5842332 ],\n",
              "       [0.6517176 , 0.30617687],\n",
              "       [0.30354235, 0.5391325 ],\n",
              "       [0.25118303, 0.5582766 ],\n",
              "       [0.39825127, 0.3906099 ],\n",
              "       [0.7765949 , 0.09259238],\n",
              "       [0.33162823, 0.52574635],\n",
              "       [0.4456408 , 0.3892428 ],\n",
              "       [0.47111818, 0.3674986 ],\n",
              "       [0.6909038 , 0.34595463],\n",
              "       [0.6707543 , 0.2546805 ],\n",
              "       [0.65074396, 0.4548264 ],\n",
              "       [0.4527675 , 0.42898124],\n",
              "       [0.19235156, 0.5649495 ],\n",
              "       [0.40706214, 0.447098  ],\n",
              "       [0.6773219 , 0.22297361],\n",
              "       [0.5504928 , 0.3172736 ],\n",
              "       [0.53003734, 0.4193617 ],\n",
              "       [0.47558308, 0.3833438 ],\n",
              "       [0.6703329 , 0.27245766],\n",
              "       [0.26294383, 0.52177894],\n",
              "       [0.5552321 , 0.18854105],\n",
              "       [0.42117855, 0.4306672 ],\n",
              "       [0.5966872 , 0.29393417],\n",
              "       [0.7538067 , 0.13475198],\n",
              "       [0.5498187 , 0.30276766],\n",
              "       [0.6372073 , 0.4120475 ],\n",
              "       [0.44136685, 0.4380066 ],\n",
              "       [0.47668007, 0.44039387],\n",
              "       [0.5499698 , 0.32661104],\n",
              "       [0.4682188 , 0.44959986],\n",
              "       [0.5863502 , 0.21654186],\n",
              "       [0.7988058 , 0.18794791],\n",
              "       [0.6693915 , 0.18417573],\n",
              "       [0.1131523 , 0.7343584 ],\n",
              "       [0.1774813 , 0.6616692 ],\n",
              "       [0.60029185, 0.23640835],\n",
              "       [0.13236901, 0.74330366],\n",
              "       [0.09743606, 0.7308823 ],\n",
              "       [0.51653016, 0.46474603],\n",
              "       [0.1555754 , 0.714774  ],\n",
              "       [0.09191791, 0.66210717],\n",
              "       [0.7143909 , 0.4519018 ],\n",
              "       [0.81888205, 0.07691752],\n",
              "       [0.79503864, 0.17898671],\n",
              "       [0.2407738 , 0.41027656],\n",
              "       [0.48114592, 0.36369622],\n",
              "       [0.31191424, 0.5255936 ],\n",
              "       [0.60317826, 0.33102873],\n",
              "       [0.39986837, 0.47749037],\n",
              "       [0.3794028 , 0.44628394],\n",
              "       [0.56682754, 0.34776756],\n",
              "       [0.45633227, 0.4167729 ],\n",
              "       [0.01342637, 0.9310862 ],\n",
              "       [0.7095805 , 0.19859806],\n",
              "       [0.29482663, 0.5148463 ],\n",
              "       [0.5671868 , 0.35466802],\n",
              "       [0.60457236, 0.18908913],\n",
              "       [0.67347056, 0.32949874],\n",
              "       [0.8239716 , 0.21894836],\n",
              "       [0.42316607, 0.42484152],\n",
              "       [0.5470377 , 0.3369006 ],\n",
              "       [0.65960014, 0.2808369 ],\n",
              "       [0.27556238, 0.5517461 ],\n",
              "       [0.5876435 , 0.31604582],\n",
              "       [0.5558076 , 0.49751213],\n",
              "       [0.11886385, 0.6918547 ],\n",
              "       [0.23835953, 0.53997654],\n",
              "       [0.51878333, 0.3392109 ],\n",
              "       [0.27296832, 0.5637633 ],\n",
              "       [0.11988138, 0.7425409 ],\n",
              "       [0.1336882 , 0.6800452 ],\n",
              "       [0.27905348, 0.59898186],\n",
              "       [0.24452594, 0.5578507 ],\n",
              "       [0.44556725, 0.3920785 ],\n",
              "       [0.5225791 , 0.37464675],\n",
              "       [0.37578467, 0.47853503],\n",
              "       [0.15091243, 0.6606353 ],\n",
              "       [0.38616428, 0.45040116],\n",
              "       [0.79226446, 0.11263793],\n",
              "       [0.481067  , 0.35407108],\n",
              "       [0.254158  , 0.48521855],\n",
              "       [0.31916353, 0.5401828 ],\n",
              "       [0.49320877, 0.3883164 ],\n",
              "       [0.42943758, 0.5691263 ],\n",
              "       [0.3782084 , 0.40502077],\n",
              "       [0.22006083, 0.58984   ],\n",
              "       [0.73555213, 0.26822948],\n",
              "       [0.37938118, 0.44521928],\n",
              "       [0.75937724, 0.18857293],\n",
              "       [0.4402694 , 0.45006913],\n",
              "       [0.36657014, 0.4838057 ],\n",
              "       [0.23704267, 0.5688652 ],\n",
              "       [0.16417296, 0.68771315],\n",
              "       [0.58240324, 0.32984394],\n",
              "       [0.37774503, 0.48123863],\n",
              "       [0.32773575, 0.5031937 ],\n",
              "       [0.18405358, 0.66688585],\n",
              "       [0.6365228 , 0.29117182],\n",
              "       [0.44541568, 0.46223104],\n",
              "       [0.3398459 , 0.5223935 ],\n",
              "       [0.48385826, 0.37294975],\n",
              "       [0.1578228 , 0.68212587],\n",
              "       [0.28511673, 0.5736415 ],\n",
              "       [0.38114548, 0.32373565],\n",
              "       [0.31628975, 0.533028  ],\n",
              "       [0.44399074, 0.4151484 ],\n",
              "       [0.5539428 , 0.25074998],\n",
              "       [0.39099506, 0.31400755],\n",
              "       [0.01204908, 0.9270067 ],\n",
              "       [0.63439035, 0.35897216],\n",
              "       [0.68008924, 0.2715353 ],\n",
              "       [0.38264662, 0.4328647 ],\n",
              "       [0.67645943, 0.34713575],\n",
              "       [0.7628119 , 0.22754563],\n",
              "       [0.20964141, 0.5728654 ],\n",
              "       [0.4756891 , 0.42764753],\n",
              "       [0.33584797, 0.5096639 ],\n",
              "       [0.26561832, 0.46542624],\n",
              "       [0.39699537, 0.5287307 ],\n",
              "       [0.44848266, 0.52683824],\n",
              "       [0.30124703, 0.55095077],\n",
              "       [0.37088934, 0.525524  ],\n",
              "       [0.6354781 , 0.27895424],\n",
              "       [0.642111  , 0.28806922],\n",
              "       [0.4944483 , 0.36837682],\n",
              "       [0.4575421 , 0.5884464 ],\n",
              "       [0.4843216 , 0.41221604],\n",
              "       [0.36112726, 0.4995808 ],\n",
              "       [0.6689509 , 0.3811186 ],\n",
              "       [0.6583964 , 0.28382882],\n",
              "       [0.22530316, 0.60125107],\n",
              "       [0.30524752, 0.527434  ],\n",
              "       [0.8750928 , 0.0566153 ],\n",
              "       [0.7565781 , 0.21143296],\n",
              "       [0.7182073 , 0.25076133],\n",
              "       [0.5150391 , 0.31790036],\n",
              "       [0.4087539 , 0.5059487 ],\n",
              "       [0.3381336 , 0.50373185],\n",
              "       [0.18657793, 0.7105123 ],\n",
              "       [0.11373282, 0.7242142 ],\n",
              "       [0.82839847, 0.10768316],\n",
              "       [0.38324782, 0.343282  ],\n",
              "       [0.05551871, 0.8256478 ],\n",
              "       [0.21314314, 0.6161645 ],\n",
              "       [0.57609254, 0.48692575],\n",
              "       [0.22046638, 0.64012796],\n",
              "       [0.3725958 , 0.4343371 ],\n",
              "       [0.6110817 , 0.19896013],\n",
              "       [0.34660614, 0.44851816],\n",
              "       [0.7151985 , 0.23117861],\n",
              "       [0.21785478, 0.52758867],\n",
              "       [0.47267652, 0.31468195],\n",
              "       [0.1929826 , 0.5982615 ],\n",
              "       [0.3527614 , 0.42751434],\n",
              "       [0.33027515, 0.4963237 ],\n",
              "       [0.5255456 , 0.28447396],\n",
              "       [0.15548782, 0.67869097],\n",
              "       [0.34335473, 0.57524455],\n",
              "       [0.1640509 , 0.6390373 ],\n",
              "       [0.13469626, 0.61180055],\n",
              "       [0.45090714, 0.58120084],\n",
              "       [0.2708013 , 0.9146436 ],\n",
              "       [0.49762878, 0.36693284],\n",
              "       [0.20881139, 0.6036337 ],\n",
              "       [0.34051564, 0.457977  ],\n",
              "       [0.88807505, 0.13810216],\n",
              "       [0.2654559 , 0.6026511 ],\n",
              "       [0.2779921 , 0.58371085],\n",
              "       [0.42048523, 0.4295906 ],\n",
              "       [0.26347035, 0.48631546],\n",
              "       [0.7623042 , 0.18767764],\n",
              "       [0.60266   , 0.25605643],\n",
              "       [0.46660376, 0.36617985],\n",
              "       [0.7327273 , 0.22295828],\n",
              "       [0.14243196, 0.7283023 ],\n",
              "       [0.2494621 , 0.57180226],\n",
              "       [0.6957485 , 0.23401682],\n",
              "       [0.7582993 , 0.12695338],\n",
              "       [0.6643194 , 0.283317  ],\n",
              "       [0.41460505, 0.3841054 ],\n",
              "       [0.5946776 , 0.2088439 ],\n",
              "       [0.40622902, 0.49218798],\n",
              "       [0.20906009, 0.57436866],\n",
              "       [0.42395708, 0.47662708],\n",
              "       [0.45704114, 0.39693874],\n",
              "       [0.40516725, 0.40656245],\n",
              "       [0.3653006 , 0.49613068],\n",
              "       [0.54611456, 0.31336877],\n",
              "       [0.72152895, 0.21690705],\n",
              "       [0.37038285, 0.47690964],\n",
              "       [0.6325449 , 0.316039  ],\n",
              "       [0.3281193 , 0.4809177 ],\n",
              "       [0.17868455, 0.5834773 ],\n",
              "       [0.6073272 , 0.34334153],\n",
              "       [0.9291253 , 0.08074175],\n",
              "       [0.83227193, 0.10290952],\n",
              "       [0.5128526 , 0.3935256 ],\n",
              "       [0.33883086, 0.53521127],\n",
              "       [0.5818405 , 0.41556984],\n",
              "       [0.31805778, 0.4681516 ],\n",
              "       [0.89596665, 0.06978084],\n",
              "       [0.76867443, 0.1335553 ],\n",
              "       [0.44387487, 0.44661924],\n",
              "       [0.34311306, 0.5150229 ],\n",
              "       [0.16405085, 0.6293791 ],\n",
              "       [0.3458096 , 0.5291084 ],\n",
              "       [0.2044054 , 0.45993513],\n",
              "       [0.6351326 , 0.26337847],\n",
              "       [0.79901016, 0.20372903],\n",
              "       [0.616448  , 0.32500824],\n",
              "       [0.2442296 , 0.61747295],\n",
              "       [0.4619711 , 0.33726904],\n",
              "       [0.57977307, 0.30651715],\n",
              "       [0.21950339, 0.45212716],\n",
              "       [0.7522352 , 0.20698716],\n",
              "       [0.22629651, 0.574164  ],\n",
              "       [0.12491119, 0.7218027 ],\n",
              "       [0.27450722, 0.5554061 ],\n",
              "       [0.55274713, 0.38086283],\n",
              "       [0.13684729, 0.6702157 ],\n",
              "       [0.70696944, 0.19460258],\n",
              "       [0.23604955, 0.6182266 ],\n",
              "       [0.02160108, 0.93026257],\n",
              "       [0.59228873, 0.30299544],\n",
              "       [0.79504883, 0.1523229 ],\n",
              "       [0.26091635, 0.5495461 ],\n",
              "       [0.74660194, 0.23888603],\n",
              "       [0.24057156, 0.6369847 ],\n",
              "       [0.4456555 , 0.4610041 ],\n",
              "       [0.48922625, 0.41083053],\n",
              "       [0.3510872 , 0.44304055],\n",
              "       [0.68516386, 0.32421964],\n",
              "       [0.5500268 , 0.24253762],\n",
              "       [0.59198815, 0.3013642 ],\n",
              "       [0.8601184 , 0.0629549 ],\n",
              "       [0.3784419 , 0.48041263],\n",
              "       [0.30161822, 0.53259283],\n",
              "       [0.4540091 , 0.43961325],\n",
              "       [0.24892928, 0.5981262 ],\n",
              "       [0.2681638 , 0.59817475],\n",
              "       [0.11468341, 0.731423  ],\n",
              "       [0.2274227 , 0.6646909 ],\n",
              "       [0.47696638, 0.44503307],\n",
              "       [0.19731317, 0.66036576],\n",
              "       [0.43217626, 0.3699491 ],\n",
              "       [0.30290455, 0.5195808 ],\n",
              "       [0.571698  , 0.3004748 ],\n",
              "       [0.39956412, 0.4688997 ],\n",
              "       [0.35173315, 0.6461634 ],\n",
              "       [0.02465245, 0.63004184],\n",
              "       [0.3524509 , 0.4904025 ],\n",
              "       [0.5238598 , 0.28724092],\n",
              "       [0.20884362, 0.74861455],\n",
              "       [0.6739466 , 0.21041913],\n",
              "       [0.35642615, 0.46103862],\n",
              "       [0.5262298 , 0.3941912 ],\n",
              "       [0.6321168 , 0.24952939],\n",
              "       [0.7581903 , 0.11736844],\n",
              "       [0.2951502 , 0.79783154],\n",
              "       [0.7313115 , 0.22565077],\n",
              "       [0.7964016 , 0.1498803 ],\n",
              "       [0.45347622, 0.25590765],\n",
              "       [0.4774005 , 0.49923918],\n",
              "       [0.57201856, 0.38827002],\n",
              "       [0.3379409 , 0.5121716 ],\n",
              "       [0.74412227, 0.18579471],\n",
              "       [0.10347572, 0.70569444],\n",
              "       [0.42346108, 0.5591    ],\n",
              "       [0.78136754, 0.10797791],\n",
              "       [0.3858344 , 0.47388276],\n",
              "       [0.42638943, 0.6052303 ],\n",
              "       [0.23177952, 0.58446234],\n",
              "       [0.28015232, 0.61283   ],\n",
              "       [0.26799196, 0.5181667 ],\n",
              "       [0.49871656, 0.34049848],\n",
              "       [0.27413443, 0.49511215],\n",
              "       [0.38442603, 0.48069155],\n",
              "       [0.02304674, 0.8646327 ],\n",
              "       [0.40742263, 0.40682423],\n",
              "       [0.28956407, 0.5414293 ],\n",
              "       [0.11229547, 0.7231895 ],\n",
              "       [0.5431311 , 0.2575596 ],\n",
              "       [0.7149956 , 0.23390959],\n",
              "       [0.68984056, 0.23257723],\n",
              "       [0.40266326, 0.48678133],\n",
              "       [0.41693127, 0.450196  ],\n",
              "       [0.54902035, 0.4496344 ],\n",
              "       [0.1982987 , 0.6671317 ],\n",
              "       [0.5624167 , 0.29682055],\n",
              "       [0.5680919 , 0.22558774],\n",
              "       [0.29094368, 0.48435006],\n",
              "       [0.32585093, 0.5317189 ],\n",
              "       [0.7091281 , 0.24390687],\n",
              "       [0.61641353, 0.3045853 ],\n",
              "       [0.4049012 , 0.40191898],\n",
              "       [0.5762258 , 0.33925194],\n",
              "       [0.31823075, 0.6411449 ],\n",
              "       [0.48947072, 0.46492153],\n",
              "       [0.520842  , 0.3981098 ],\n",
              "       [0.2820426 , 0.49709716],\n",
              "       [0.31415284, 0.4875011 ],\n",
              "       [0.25152278, 0.59572494],\n",
              "       [0.02315203, 0.8559847 ],\n",
              "       [0.14292346, 0.6527489 ],\n",
              "       [0.30809608, 0.33395326],\n",
              "       [0.3700704 , 0.44256485],\n",
              "       [0.70057935, 0.25029114],\n",
              "       [0.610817  , 0.26907414],\n",
              "       [0.44842485, 0.40390888],\n",
              "       [0.28207588, 0.5060393 ],\n",
              "       [0.56655335, 0.43253517],\n",
              "       [0.29180256, 0.46836597],\n",
              "       [0.2481161 , 0.3232145 ],\n",
              "       [0.58748126, 0.3318311 ],\n",
              "       [0.31474677, 0.49166113],\n",
              "       [0.53240645, 0.35609397],\n",
              "       [0.3409964 , 0.4818063 ],\n",
              "       [0.27529252, 0.5446264 ],\n",
              "       [0.38453957, 0.4576839 ],\n",
              "       [0.5887607 , 0.3324893 ],\n",
              "       [0.79545796, 0.15731965],\n",
              "       [0.44534677, 0.4406198 ],\n",
              "       [0.49284157, 0.33161405],\n",
              "       [0.68011886, 0.26434967],\n",
              "       [0.2902966 , 0.53641015],\n",
              "       [0.28124586, 0.8409379 ],\n",
              "       [0.1758246 , 0.72744465],\n",
              "       [0.25642744, 0.6840301 ],\n",
              "       [0.1521738 , 0.7226915 ],\n",
              "       [0.31124035, 0.32051262],\n",
              "       [0.4656172 , 0.4464886 ],\n",
              "       [0.3258148 , 0.5263053 ],\n",
              "       [0.23655163, 0.5057899 ],\n",
              "       [0.42553547, 0.34953555],\n",
              "       [0.7278552 , 0.207817  ],\n",
              "       [0.2357063 , 0.61839163],\n",
              "       [0.4839847 , 0.37092814],\n",
              "       [0.53345144, 0.3623798 ],\n",
              "       [0.59457403, 0.2964235 ],\n",
              "       [0.04256183, 0.81143963],\n",
              "       [0.5655677 , 0.4293074 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_classes = [np.argmax(i) for i in y_pred]\n",
        "y_classes[:]"
      ],
      "metadata": {
        "id": "qi1pNSpzKpCj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a891df4f-4c45-4987-a1b6-8ead9691abbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = ['Real' if label == 1 else 'AI' for label in y_classes]\n",
        "ids = list(y_classes)\n",
        "print(\"ids:\", ids[:5])\n",
        "print(\"labels:\", labels[:5])\n"
      ],
      "metadata": {
        "id": "hjbplIOuOtk6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8896cea8-2814-441d-d700-73813554a168"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ids: [0, 0, 0, 0, 1]\n",
            "labels: ['AI', 'AI', 'AI', 'AI', 'Real']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ids[:])\n",
        "print(labels[:])"
      ],
      "metadata": {
        "id": "zV86pHFaPCPU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60e2911e-4a50-4972-bd35-a4d3b1fc02fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0]\n",
            "['AI', 'AI', 'AI', 'AI', 'Real', 'Real', 'Real', 'Real', 'AI', 'Real', 'Real', 'AI', 'Real', 'AI', 'Real', 'Real', 'AI', 'Real', 'Real', 'Real', 'AI', 'Real', 'Real', 'AI', 'AI', 'AI', 'AI', 'Real', 'Real', 'Real', 'Real', 'AI', 'AI', 'Real', 'Real', 'Real', 'Real', 'AI', 'Real', 'AI', 'AI', 'Real', 'Real', 'Real', 'AI', 'AI', 'Real', 'Real', 'AI', 'Real', 'Real', 'Real', 'Real', 'Real', 'Real', 'AI', 'AI', 'AI', 'Real', 'AI', 'Real', 'Real', 'Real', 'Real', 'AI', 'Real', 'Real', 'Real', 'AI', 'AI', 'Real', 'AI', 'AI', 'Real', 'Real', 'Real', 'Real', 'AI', 'Real', 'Real', 'AI', 'AI', 'Real', 'Real', 'AI', 'AI', 'Real', 'AI', 'Real', 'Real', 'Real', 'AI', 'Real', 'Real', 'AI', 'Real', 'Real', 'Real', 'Real', 'Real', 'AI', 'Real', 'AI', 'Real', 'Real', 'AI', 'Real', 'Real', 'Real', 'AI', 'AI', 'Real', 'AI', 'Real', 'AI', 'Real', 'AI', 'AI', 'Real', 'Real', 'AI', 'AI', 'Real', 'Real', 'AI', 'Real', 'AI', 'AI', 'Real', 'Real', 'Real', 'Real', 'AI', 'AI', 'Real', 'Real', 'Real', 'AI', 'AI', 'Real', 'AI', 'AI', 'Real', 'Real', 'Real', 'AI', 'Real', 'AI', 'AI', 'Real', 'Real', 'AI', 'Real', 'AI', 'Real', 'AI', 'Real', 'AI', 'Real', 'AI', 'Real', 'Real', 'AI', 'AI', 'Real', 'AI', 'AI', 'AI', 'AI', 'AI', 'AI', 'Real', 'Real', 'AI', 'AI', 'AI', 'AI', 'AI', 'Real', 'AI', 'Real', 'AI', 'AI', 'AI', 'AI', 'AI', 'AI', 'AI', 'AI', 'AI', 'AI', 'AI', 'Real', 'Real', 'AI', 'Real', 'Real', 'AI', 'Real', 'Real', 'AI', 'AI', 'AI', 'Real', 'AI', 'Real', 'AI', 'Real', 'Real', 'AI', 'AI', 'Real', 'AI', 'Real', 'AI', 'AI', 'AI', 'AI', 'Real', 'AI', 'AI', 'Real', 'AI', 'AI', 'Real', 'Real', 'AI', 'Real', 'Real', 'Real', 'Real', 'Real', 'AI', 'AI', 'Real', 'Real', 'Real', 'AI', 'AI', 'Real', 'Real', 'AI', 'Real', 'Real', 'Real', 'AI', 'Real', 'AI', 'Real', 'Real', 'Real', 'Real', 'AI', 'Real', 'Real', 'Real', 'AI', 'Real', 'Real', 'AI', 'Real', 'Real', 'AI', 'Real', 'AI', 'AI', 'AI', 'Real', 'AI', 'AI', 'Real', 'AI', 'AI', 'Real', 'AI', 'Real', 'Real', 'Real', 'Real', 'Real', 'Real', 'AI', 'AI', 'AI', 'Real', 'AI', 'Real', 'AI', 'AI', 'Real', 'Real', 'AI', 'AI', 'AI', 'AI', 'Real', 'Real', 'Real', 'Real', 'AI', 'AI', 'Real', 'Real', 'AI', 'Real', 'Real', 'AI', 'Real', 'AI', 'Real', 'AI', 'Real', 'Real', 'Real', 'AI', 'Real', 'Real', 'Real', 'Real', 'Real', 'Real', 'AI', 'Real', 'Real', 'AI', 'Real', 'Real', 'Real', 'Real', 'AI', 'AI', 'AI', 'AI', 'Real', 'Real', 'AI', 'AI', 'AI', 'AI', 'AI', 'Real', 'Real', 'Real', 'AI', 'Real', 'Real', 'AI', 'AI', 'Real', 'AI', 'Real', 'Real', 'AI', 'AI', 'AI', 'AI', 'Real', 'AI', 'Real', 'AI', 'AI', 'Real', 'Real', 'Real', 'Real', 'Real', 'AI', 'AI', 'AI', 'Real', 'AI', 'AI', 'Real', 'AI', 'Real', 'Real', 'Real', 'AI', 'Real', 'AI', 'Real', 'Real', 'AI', 'AI', 'Real', 'AI', 'Real', 'Real', 'AI', 'Real', 'AI', 'AI', 'AI', 'AI', 'Real', 'Real', 'AI', 'Real', 'Real', 'Real', 'Real', 'AI', 'Real', 'AI', 'Real', 'AI', 'Real', 'Real', 'Real', 'Real', 'AI', 'Real', 'AI', 'Real', 'AI', 'AI', 'AI', 'Real', 'AI', 'AI', 'AI', 'Real', 'AI', 'Real', 'AI', 'Real', 'Real', 'AI', 'Real', 'Real', 'Real', 'Real', 'Real', 'AI', 'Real', 'Real', 'Real', 'AI', 'Real', 'Real', 'AI', 'AI', 'AI', 'Real', 'Real', 'AI', 'Real', 'AI', 'AI', 'Real', 'Real', 'AI', 'AI', 'AI', 'AI', 'Real', 'AI', 'AI', 'Real', 'Real', 'Real', 'Real', 'Real', 'Real', 'Real', 'AI', 'AI', 'AI', 'Real', 'AI', 'Real', 'Real', 'AI', 'Real', 'AI', 'Real', 'Real', 'Real', 'AI', 'AI', 'AI', 'AI', 'AI', 'Real', 'Real', 'Real', 'Real', 'Real', 'Real', 'AI', 'Real', 'Real', 'AI', 'AI', 'Real', 'AI', 'AI', 'AI', 'Real', 'AI']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({'id': ids, 'label': labels})"
      ],
      "metadata": {
        "id": "HyLiS_1sQOPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #Save this DataFrame to CSV file\n",
        "df.to_csv('output3.csv', index=False)\n",
        "print(\"DataFrame saved to 'output.csv'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9biZFZ1RRmx",
        "outputId": "934c0aa0-7d44-4fc1-b291-688bd8f25c61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved to 'output.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T2p86Vy6RX8Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}