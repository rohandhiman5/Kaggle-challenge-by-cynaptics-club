{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPTgUdFA9W7Dke4fJcXGrY6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rohandhiman5/Kaggle-challenge-by-cynaptics-club/blob/main/splitting_of_folder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kx8eATnBGpDG",
        "outputId": "25fbb779-3f6d-491e-daaa-4fbf247621b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n",
            "spot-the-synthetic.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ],
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle competitions download spot-the-synthetic"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "file = 'spot-the-synthetic.zip'\n",
        "with ZipFile(file, 'r') as zip:\n",
        "    zip.extractall()"
      ],
      "metadata": {
        "id": "q2yv80WKGzZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "qaa--LgBG2tT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create ai and real imaage folder in a folder\n",
        "import os\n",
        "import shutil\n",
        "def select_first_two_folders(folder_path):\n",
        "    folders = [f for f in os.listdir(folder_path) if os.path.isdir(os.path.join(folder_path, f))]\n",
        "    selected_folders = folders[0:3:2]\n",
        "    return selected_folders\n",
        "\n",
        "source_folder_path = '/content/Data'\n",
        "destination_folder_path = 'images'\n",
        "\n",
        "selected_folders = select_first_two_folders(source_folder_path)\n",
        "if not os.path.exists(destination_folder_path):\n",
        "    os.makedirs(destination_folder_path)\n",
        "\n",
        "for folder in selected_folders:\n",
        "    source = os.path.join(source_folder_path, folder)\n",
        "    destination = os.path.join(destination_folder_path, folder)\n",
        "    shutil.copytree(source, destination)\n",
        "    print(f\"Folder '{folder}' copied to '{destination_folder_path}'\")\n"
      ],
      "metadata": {
        "id": "TaK_YGT7G4gB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create test and validate data folderr\n",
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "base_dir = '/content/images'\n",
        "filter_dir = os.path.join(base_dir, 'filter')\n",
        "test_dir = os.path.join(filter_dir, 'test')\n",
        "validate_dir = os.path.join(filter_dir, 'validate')\n",
        "os.makedirs(test_dir, exist_ok=True)\n",
        "os.makedirs(validate_dir, exist_ok=True)\n",
        "\n",
        "test_ai_images_dir = os.path.join(test_dir, 'AI_Images')\n",
        "test_real_images_dir = os.path.join(test_dir, 'Real_Images')\n",
        "validate_ai_images_dir = os.path.join(validate_dir, 'AI_Images')\n",
        "validate_real_images_dir = os.path.join(validate_dir, 'Real_Images')\n",
        "\n",
        "os.makedirs(test_ai_images_dir, exist_ok=True)\n",
        "os.makedirs(test_real_images_dir, exist_ok=True)\n",
        "os.makedirs(validate_ai_images_dir, exist_ok=True)\n",
        "os.makedirs(validate_real_images_dir, exist_ok=True)\n",
        "\n",
        "AI_Images = os.listdir(os.path.join(base_dir, 'AI_Images'))\n",
        "Real_Images = os.listdir(os.path.join(base_dir, 'Real_Images'))\n",
        "\n",
        "test_ai_images, validate_ai_images = train_test_split(AI_Images, train_size=0.8, random_state=42)\n",
        "test_real_images, validate_real_images = train_test_split(Real_Images, train_size=0.8, random_state=42)\n",
        "\n",
        "for image in test_ai_images:\n",
        "    shutil.move(os.path.join(base_dir, 'AI_Images', image), os.path.join(test_ai_images_dir, image))\n",
        "\n",
        "for image in test_real_images:\n",
        "    shutil.move(os.path.join(base_dir, 'Real_Images', image), os.path.join(test_real_images_dir, image))\n",
        "\n",
        "for image in validate_ai_images:\n",
        "    shutil.move(os.path.join(base_dir, 'AI_Images', image), os.path.join(validate_ai_images_dir, image))\n",
        "\n",
        "for image in validate_real_images:\n",
        "    shutil.move(os.path.join(base_dir, 'Real_Images', image), os.path.join(validate_real_images_dir, image))\n",
        "\n",
        "print(\"Data split into test and validate sets.\")\n"
      ],
      "metadata": {
        "id": "15_rActVG_U9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = '/content/images/filter'\n",
        "train_dir = os.path.join(base_dir, 'test')\n",
        "validation_dir = os.path.join(base_dir, 'validate')"
      ],
      "metadata": {
        "id": "HO-juw_0H8k9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ai_dir = os.path.join(train_dir, 'AI_Images')\n",
        "\n",
        "train_real_dir = os.path.join(train_dir, 'Real_Images')\n",
        "\n",
        "validation_ai_dir = os.path.join(validation_dir, 'AI_Images')\n",
        "\n",
        "validation_real_dir = os.path.join(validation_dir, 'Real_Images')"
      ],
      "metadata": {
        "id": "-KFi6cF3JooQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1.0/255., rotation_range = 40, width_shift_range = 0.2, height_shift_range = 0.2,shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n",
        "\n",
        "test_datagen = ImageDataGenerator( rescale = 1.0/255. )"
      ],
      "metadata": {
        "id": "VWVAhXqAKLKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_directory(train_dir, batch_size = 20, class_mode = 'binary', target_size = (224, 224))\n",
        "validation_generator = test_datagen.flow_from_directory(validation_dir, batch_size = 20, class_mode = 'binary', target_size = (224, 224))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uc94fHZKPBH",
        "outputId": "25dc3c69-9f60-4ccd-9d48-5b2e15f088f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1004 images belonging to 2 classes.\n",
            "Found 251 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "base_model = InceptionV3(input_shape = (224,224, 3), include_top = False, weights = 'imagenet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQ-3NBWgKRZs",
        "outputId": "b0b16829-03be-446f-deac-05848e583443"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87910968/87910968 [==============================] - 5s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in base_model.layers:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "w1Pc5pAMKVtg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "x = layers.Flatten()(base_model.output)\n",
        "\n",
        "x = layers.Dense(512, activation='relu')(x)\n",
        "\n",
        "x = layers.Dropout(0.5)(x)\n",
        "\n",
        "x = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = tf.keras.models.Model(base_model.input, x)\n",
        "\n",
        "model.compile(optimizer = tf.keras.optimizers.RMSprop(lr=0.0001), loss = 'binary_crossentropy',metrics = ['acc'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALAZ2-SqKZWE",
        "outputId": "35dc5be4-12ef-44ac-9a46-bd05e070461a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inc_history = model.fit_generator(train_generator, validation_data = validation_generator, steps_per_epoch = 50, epochs = 30)"
      ],
      "metadata": {
        "id": "N0h2CHRbKeOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('model1.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FjC3nJfKn1B",
        "outputId": "3cc68df9-acaa-4573-8e87-161ff0acb700"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "joblib.dump(model, 'model_filename.pkl')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7TaE_NDwPEr",
        "outputId": "4aa35318-20ea-40b1-fa5e-a7245a8e9206"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['model_filename.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input, decode_predictions\n",
        "import os\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "li_i21yiyR_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import os\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "\n",
        "\n",
        "test_images_folder = '/content/Data/Test_Images'\n",
        "\n",
        "\n",
        "image_filenames = os.listdir(test_images_folder)\n",
        "\n",
        "\n",
        "results = []\n",
        "\n",
        "\n",
        "for filename in image_filenames:\n",
        "\n",
        "    img_path = os.path.join(test_images_folder, filename)\n",
        "    img = image.load_img(img_path, target_size=(224, 224))\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = preprocess_input(img_array)\n",
        "\n",
        "\n",
        "    predictions = model.predict(img_array.reshape(1, 224, 224, 3))\n",
        "\n",
        "\n",
        "    predicted_class = predictions[0][0]\n",
        "    predicted_label = \"Real\" if predicted_class < 0.5 else \"AI\"\n",
        "\n",
        "\n",
        "    image_id = int(filename.split('.')[0].split('_')[1])\n",
        "\n",
        "    results.append({'Id': image_id, 'Label': predicted_label})\n",
        "\n",
        "results.sort(key=lambda x: x['Id'])\n",
        "\n",
        "csv_file_path = 'rohan21.csv'\n",
        "\n",
        "\n",
        "with open(csv_file_path, mode='w', newline='') as file:\n",
        "    writer = csv.DictWriter(file, fieldnames=['Id', 'Label'])\n",
        "    writer.writeheader()\n",
        "    for result in results:\n",
        "        writer.writerow(result)\n",
        "\n",
        "print(f\"Predictions saved to '{csv_file_path}'\")\n",
        "\n"
      ],
      "metadata": {
        "id": "AQ_cPQFIvLCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_pred[:]"
      ],
      "metadata": {
        "id": "o-ZXumYuvkbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_classes = [np.argmax(element) for element in y_pred]\n",
        "y_classes[:]"
      ],
      "metadata": {
        "id": "ZhZfxgkVvpZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = ['Real' if label == 1 else 'AI' for label in y_classes]\n",
        "ids = list(y_classes)\n",
        "# Print the first few elements of id and label for verification\n",
        "print(\"ids:\", ids[:5])  # Print the first 5 elements of ids\n",
        "print(\"labels:\", labels[:5])  # Print the first 5 elements of labels\n"
      ],
      "metadata": {
        "id": "SAZZ0bK0vsN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(ids[:])\n",
        "print(labels[:])"
      ],
      "metadata": {
        "id": "t9-nH62evvHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "GS7Vq3qgv5I-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({'id': ids, 'label': labels})"
      ],
      "metadata": {
        "id": "r92Vp0bbvxYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DtxRUeyqDcd2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}